#!/usr/bin/python
import nltk
def wordCount(filename):
   file=open(filename,"r+")
   wordcount={};
   for word in file.read().split():
       if word not in wordcount:
           wordcount[word] = 1;
       else:
           wordcount[word] += 1;
   
   return wordcount;       
   
   #!/usr/bin/python
def NNCount(filename):
   file=open(filename,"r+")
   sentence=[];
   parsedList=[];
   sentenceList=[];
   numofNN=0;
   for line in ins:
      sentence.append(line)
      if(line(len(line.strip())-1)=='.'):
         sentenceList.append(''.join(sentence))
         tokens = nltk.word_tokenize(''.join(sentence))
         tagged = nltk.pos_tag(tokens)
         parcedList.append(tagged)
         sentence=[];
   for taggedSentence in parsedList:
       for tag in taggedSentence:
           if(tag[1]=='NN'):
               numofNN=numofNN+1
   
   return numofNN            
             
   ins.close() 
    
   
   #!/usr/bin/python
def avgSentComplexity(filename):
   file=open(filename,"r+")
   parser = nltk.ChartParser(groucho_grammar)
   sentence=[]
   count=0
   numSentences=0
   numofNN=0;
   for line in ins:
      sentence.append(line)
      if(line(len(line.strip())-1)=='.'):
         count=count+(parser.parse(sentence)).count(')')+(parser.parse(sentence)).count('(')
         sentence=[]
         numSentences=numSentences+1
      
   averageComplexity=count/numSentences
   return averageComplexity
   
def getFeatures(numFiles)
    allwordstogetherList=[]
    wordCountDictList=[]
    complexityList=[]
    NNList=[]
    for i in range(0,numFiles):
        complexityList.append(avgSentComplexity('%d.txt' % i)) 
        NNList.append(NNCount('%d.txt' % i)) 
        temp=wordCount('%d.txt' % i)
        allwordstogetherList=allwordstogetherList+temp.keys()
        wordCountDictList.append(temp)
    
    uniqueWordList=list(set(allwordstogetherList))
    file = open("uniqueWordList.txt", "w")
    for item in uniqueWordList:
        file.write("%s\n" % item)
    file.close()
    uniWord=open("uniqueWordList.txt", "w")  #create label?
    uniWord.close()
    with open("labels.txt", "a") as f:
        for i2 in range(-1,numFiles):
            f.write("1\n")
    feat=open("features.txt", "w")  #create features.txt?
    feat.close()
    with open("features.txt", "a") as f2:
        for i3 in range(0,numFiles):
            f2.write('%(Complexity)d %(NN)d ' % \{"Complexity": complexityList(i3), "NN": NNList(i3)})
            for word in uniqueWordList
                tempDict=wordCountDictList(i3)
                if tempDict.has_key(word):
                    f2.write('%d ' % tempDict[word])
                else:
                    f2.write('0')
                
            f2.write('\n')
    
    
    
    
             
   