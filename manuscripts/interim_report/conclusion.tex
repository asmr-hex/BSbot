% conclusion

So far we have gathered features and found the most determinant ones for classifying between generated High Energy Particle Physics Abstracts and real, written High Energy Particle Physics Abstract.  We did this through a series of methods we created, as described above, to weigh the features based on the hamming distance between their frequency graphs.  With these weighted features we will be able to find a metric for effectively judging the performance of several classification schemes on our data.  We are well prepared to continue using this data to do an in depth evaluation of several classification methods.  With the feature extraction code we have already implemented it is easy to add more features to our list and judge them very efficiently.

In the future we plan to add many more types of features.  We also plan on finding or creating other separation methods to judge against.  These metrics include other feature sets and other classifiers such as Logistic Regression and KNN grouping.  We also plan to find out how well humans do in classifying these Abstracts.  Our initial information on this says that humans do a very poor job of classifying the abstracts.  If we can achieve a higher correct classification percentage than humans then that will be a good first step.  We plan on implementing sentence complexity by analyzing the syntax and tagged trees and finding their depth and width.  We need to establish a grammar file to compute these trees effectively and this will take some time but should be a very attainable future goal.  We also plan on implementing other counts of tagged words.  We have looked at several kernels as well.  Many of these string kernels work on k-mers and the hamming distance between these k-mers and the words that they are derived from.  We will experiment with several of these kernels and use cross validation over our training set to find the one most effective in establishing separation.