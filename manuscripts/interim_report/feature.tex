% feature selection
% Connor Walsh -  11/2/2014

%Bag-Of-Words and beyond...
Naturally, when presented with a dataset comprised wholly of text strings, the prevailing response is to employ a \emph{Bag-of-words} approach in feature selection in which a dictionary of chosen words or phrases are used to discriminate between multiple document classes. While this feature selection method certainly has merit, the information it conveys is limited due to the loss of structure imposed during feature transformation. For this reason, we incorporate additional features which preserve some syntactic structure in order to exploit our prior knowledge of context-free grammar.

We also implement a series of lexical parsers.  For example, we use NLTK to do part of speech tagging in each sentence for each document sample.  This allows us to us the counts of each tag as a separate feature.  We generate a sentence tree for each sentence.  This allows us to use features that include the depth and breadth of the sentence to judge complexity overall for each document.  One interesting extra feature drawn from this is the ambiguity of noun reference.  When a sentence is referentially ambiguous, two trees are generated.  This allows us to judge the average incidences of referential ambiguity in a document and use this as a feature.  This feature, combined with sentence complexity, should be effective at discriminating between the two classes.  The Corpus used for lexical parsing is the generic Brown Corpus though we will experiment with several others.

%Scoring Features
While carefully premeditating the types of features to include in the final learning system is crucial for an accurate classifier, often it is unclear which features will yield optimal performance. For a binary linear discriminant learner, the accuracy of performance manifests itself as the margin of separability between classes of high dimensional features. Thus, it is absolutely critical to evaluate the candidate features with respect to their separability between classes.

To this end, we have developed a method to filter the best features in terms of the information they convey for class discrimination. The method we present draw on previous work and is designed to evaluate generic feature types \cite{french}.
DISCRIBE HISTOGRAM METRICS.